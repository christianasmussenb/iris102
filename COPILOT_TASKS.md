# COPILOT_TASKS.md - Criterios de Aceptaci√≥n y Lista de Tareas

## Criterios de Aceptaci√≥n Principal

### 1. Procesamiento Autom√°tico de Archivos ‚úÖ Infraestructura Lista
**Criterio**: Al copiar `file1.csv` a `./data/IN/`, el Service lo detecta, procesa y lo mueve a `./data/OUT/` renombrado con timestamp y status.

**Validaci√≥n**:
- [ ] Archivo detectado autom√°ticamente en m√°ximo 10 segundos
- [ ] Archivo movido a OUT con formato: `<nombre>__YYYYMMDD_HHMMSS__<status>.csv`
- [ ] Status correcto: `ok`, `partial`, `error`, `duplicate`
- [ ] Archivo original removido de IN

### 2. Inserci√≥n en Bases de Datos ‚è≥ Pendiente Sprint 5
**Criterio**: Registros insertados en **MySQL** y **PostgreSQL** (si Postgres falla, status `partial` y se loggea).

**Validaci√≥n**:
- [ ] Datos insertados correctamente en MySQL local
- [ ] Datos insertados correctamente en PostgreSQL externo
- [ ] Manejo de fallas parciales (MySQL ok, PostgreSQL fail ‚Üí status `partial`)
- [ ] Prevenci√≥n de SQL injection con queries parametrizadas
- [ ] Upsert por clave natural (external_id, occurred_at)

### 3. Sistema de Logging ‚è≥ Pendiente Sprint 2
**Criterio**: Logs creados en `./data/LOG/ingest_YYYYMMDD.log` con l√≠neas START/END y m√©tricas.

**Validaci√≥n**:
- [ ] Archivo de log diario creado autom√°ticamente
- [ ] L√≠nea START con: timestamp, filename, size, hash
- [ ] L√≠nea END con: timestamp, filename, status, m√©tricas de procesamiento
- [ ] Event Log de IRIS con eventos de proceso
- [ ] Logs de errores detallados con stack traces

### 4. Tolerancia a Fallas y Duplicados ‚è≥ Pendiente Sprint 3
**Criterio**: Reintentos implementados en las Operations y sin duplicados si el mismo archivo entra dos veces.

**Validaci√≥n**:
- [ ] Detecci√≥n de duplicados por hash SHA256
- [ ] Archivo duplicado movido a OUT con status `duplicate`
- [ ] Reintentos con backoff exponencial (3 intentos: 0.5s, 2s, 5s)
- [ ] Fallas transitorias manejadas correctamente
- [ ] Recuperaci√≥n autom√°tica despu√©s de fallos de red/DB

### 5. Configuraci√≥n por Variables de Entorno ‚úÖ Completado
**Criterio**: Toda la configuraci√≥n sensible viene desde `.env`.

**Validaci√≥n**:
- [x] No hay passwords hardcodeados en el c√≥digo
- [x] Todas las conexiones DB configurables por ENV
- [x] Rutas de archivos configurables
- [x] Par√°metros de retry y timeouts configurables
- [x] Template `.env.example` documentado

### 6. Despliegue con Docker Compose ‚úÖ Completado
**Criterio**: `docker-compose up` levanta IRIS + MySQL; con Postgres externo configurable por ENV.

**Validaci√≥n**:
- [x] IRIS Community ejecut√°ndose y accesible
- [x] MySQL local inicializado con tablas
- [x] Adminer funcional para gesti√≥n de MySQL
- [x] PostgreSQL local opcional para testing
- [x] Vol√∫menes persistentes configurados
- [x] Red de contenedores configurada correctamente

### 7. Documentaci√≥n y Usabilidad ‚úÖ Completado
**Criterio**: README con pasos: `docker-compose up`, configurar connections en IRIS si aplica, prueba con el sample, verificaci√≥n en MySQL/Postgres, d√≥nde ver logs/eventos.

**Validaci√≥n**:
- [x] README con instrucciones paso a paso
- [x] Secci√≥n de troubleshooting
- [x] Ejemplos de uso con archivos CSV
- [x] Comandos para verificar funcionamiento
- [x] Documentaci√≥n de variables de entorno

## Lista de Tareas por Sprint

### Sprint 1: Infraestructura Base ‚úÖ COMPLETADO
- [x] Estructura de carpetas completa
- [x] Docker Compose con todos los servicios
- [x] Scripts SQL de inicializaci√≥n
- [x] Variables de entorno y configuraci√≥n
- [x] Dockerfile de IRIS personalizado
- [x] Script de inicializaci√≥n autom√°tica
- [x] Clase Installer.cls
- [x] Archivos CSV de muestra
- [x] README completo

### Sprint 2: Clases Base de InterSystems IRIS ‚úÖ COMPLETADO
- [x] Demo.Production.cls - Configuraci√≥n de la Production
- [x] Demo.Msg.Record.cls - Mensajes Request/Response  
- [x] Demo.Util.Logger.cls - Utilidades de logging y hash
- [x] Configuraci√≥n de adaptadores EnsLib
- [x] Compilaci√≥n y carga autom√°tica

### Sprint 3: Business Service - Detecci√≥n de Archivos ‚è≥ PENDIENTE
- [ ] Demo.FileService.cls con EnsLib.File.InboundAdapter
- [ ] Configuraci√≥n de FileSpec="file*.csv"
- [ ] C√°lculo de hash SHA256 para duplicados
- [ ] Movimiento y renombrado de archivos
- [ ] Logging de eventos de procesamiento

### Sprint 4: Business Process - Parser CSV ‚è≥ PENDIENTE  
- [ ] Demo.BPL.Process.bpl o Demo.Process.cls
- [ ] Parser CSV robusto con manejo de cabeceras
- [ ] Validaci√≥n de tipos de datos
- [ ] Coordinaci√≥n de m√∫ltiples operaciones
- [ ] Manejo de respuestas y errores

### Sprint 5: Business Operations - Conectores DB ‚è≥ PENDIENTE
- [ ] Demo.MySQL.Operation.cls 
- [ ] Demo.Postgres.Operation.cls
- [ ] Configuraci√≥n de DSN/JDBC
- [ ] Queries parametrizadas y upserts
- [ ] Sistema de reintentos con backoff

### Sprint 6: Integraci√≥n y Testing ‚è≥ PENDIENTE
- [ ] Flujo end-to-end completo
- [ ] Pruebas con archivos CSV reales
- [ ] Pruebas de tolerancia a fallas
- [ ] Configuraci√≥n de PostgreSQL externo
- [ ] Performance testing

### Sprint 7: Documentaci√≥n y Refinamiento ‚è≥ PENDIENTE
- [ ] Documentaci√≥n t√©cnica completa
- [ ] Gu√≠as de troubleshooting detalladas
- [ ] Optimizaciones de performance
- [ ] Criterios de aceptaci√≥n verificados
- [ ] Release notes y changelog

## Tests de Aceptaci√≥n Automatizados

### Test 1: Procesamiento B√°sico
```bash
# 1. Copiar archivo de muestra
cp data/samples/file1.csv data/IN/file_test1.csv

# 2. Esperar procesamiento (max 30 segundos)
timeout 30 bash -c 'while [[ -f data/IN/file_test1.csv ]]; do sleep 1; done'

# 3. Verificar archivo en OUT
ls data/OUT/file_test1__*__*.csv

# 4. Verificar datos en MySQL
docker exec iris102-mysql mysql -udemo -pdemo_pass demo -e "SELECT COUNT(*) FROM records WHERE source_file LIKE '%file_test1%';"

# 5. Verificar logs
grep "file_test1" data/LOG/ingest_$(date +%Y%m%d).log
```

### Test 2: Detecci√≥n de Duplicados  
```bash
# 1. Procesar archivo original
cp data/samples/file1.csv data/IN/file_dup_test.csv
sleep 10

# 2. Intentar procesar el mismo archivo
cp data/samples/file1.csv data/IN/file_dup_test2.csv  
sleep 10

# 3. Verificar que el segundo tiene status duplicate
ls data/OUT/file_dup_test2__*__duplicate.csv
```

### Test 3: Manejo de Errores
```bash
# 1. Crear archivo CSV con formato inv√°lido
echo "invalid,csv,data" > data/IN/invalid_test.csv
sleep 10

# 2. Verificar que se marca como error
ls data/OUT/invalid_test__*__error.csv

# 3. Verificar logs de error
grep "ERROR" data/LOG/ingest_$(date +%Y%m%d).log
```

## M√©tricas de Calidad

- **Cobertura de C√≥digo**: >80% en clases principales
- **Performance**: Procesar 1000 registros en <30 segundos  
- **Disponibilidad**: Sistema recuperable en <2 minutos tras fallo
- **Logs**: Trazabilidad completa de cada archivo procesado
- **Seguridad**: No exposici√≥n de credenciales en logs o c√≥digo

## Estado de Progreso

- ‚úÖ **Completado**: 2/7 Sprints (29%)
- üîÑ **Siguiente**: Sprint 3 - Business Service (detecci√≥n de archivos)
- ‚è≥ **Pendiente**: Sprints 4-7
- üéØ **Objetivo**: Completar todos los criterios de aceptaci√≥n

### Resumen de Avances

**Sprint 1 ‚úÖ**: Infraestructura Docker completa con IRIS, MySQL, PostgreSQL
**Sprint 2 ‚úÖ**: Clases base ObjectScript, mensajes, utilidades, Production configurada
**Sprint 3 ‚è≥**: Implementaci√≥n completa de Demo.FileService
**Sprint 4 ‚è≥**: Parser CSV y orquestaci√≥n en Demo.Process
**Sprint 5 ‚è≥**: Operaciones de base de datos MySQL y PostgreSQL
**Sprint 6 ‚è≥**: Integraci√≥n end-to-end y testing
**Sprint 7 ‚è≥**: Documentaci√≥n final y refinamiento

---

**√öltima actualizaci√≥n**: 14 de octubre de 2025  
**Pr√≥xima revisi√≥n**: Completar Sprint 2